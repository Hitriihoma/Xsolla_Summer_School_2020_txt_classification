{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do:\n",
    "1. Текст был очищен только от одного мусорного элемента в качестве примера. Исследуйте данные через ноутбук или через веб-интерфейс BigQuery на предмет других мусорных элементов в тексте, которые не несут в себе никакого особого смысла, а только создают шум в данных. Доработайте функцию очистки тектосвых данных, чтобы в нее можно было передать список ненужного мусора и разом выполнялась очистка\n",
    "2. Проведите стратифицировнную кросс-валидацию нейросетевого классификатора https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "3. Реверс-инжениринг нейронной сети (вектор - фразы - частотный анализ встречаемых слов - удаление или добавление в модель)\n",
    "\n",
    "НЕ НАДО 3. Поэксперементируйте с гиперпараметрами нейросетевого классификатора, постарайтесь повысить качество его работы\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "4. Попробуйте использовать не Word2Vec для получения векторого представления текста, а TF-IDF преобразование http://zabaykin.ru/?p=558 http://nlpx.net/archives/57\n",
    "5. Попробуйте использовать более тонко настриваемые алгоритмы нейросетей, например из этого видео https://www.youtube.com/watch?v=cPkH1k3U1c8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import datetime as dt\n",
    "\n",
    "from langdetect import detect\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for getting fresh data from DWH for workload model\n",
    "\"\"\"[summary]\n",
    "Funtion for getting fresh data from BigQuery for workload scoring model\n",
    "[description]\n",
    "Credentials - google service account object with credentials data for project\n",
    "[example]\n",
    "Input: Credentials = credentials_object\n",
    "Output: description\t                                        channel\t category\tcategory_flag\n",
    "        \\nChat transcript:\\nVisitor: I want to buy wit...\tchat\t ps\t        1\n",
    "        \\nChat transcript:\\nVisitor: hell i had a prob...\tchat\t ps\t        1\n",
    "        \\nChat transcript:\\nVisitor: لا استطيع الشراء ...\t chat\t  ps\t     1\n",
    "\"\"\"\n",
    "def getDwhData(Credentials):\n",
    "    statement_bigquery_sql = \" \".join([\"select description, channel, case\",\n",
    "                                       \"when manual_category in ('payment_problem','how_to_pay','howtopay','how_to_play','paystation_error','ps_problem','ps_declined') then 'ps'\",\n",
    "                                       \"else 'other'\",\n",
    "                                       \"end as category,\",\n",
    "                                       \"case\",\n",
    "                                       \"when manual_category in ('payment_problem','how_to_pay','howtopay','how_to_play','paystation_error','ps_problem','ps_declined') then 0\",\n",
    "                                       \"else 1\",\n",
    "                                       \"end as category_flag\",\n",
    "                                       \"from `xsolla_summer_school.customer_support`\",\n",
    "                                       \"where manual_category is not null and\",\n",
    "                                       \"manual_category <> '' and\",\n",
    "                                       \"description is not null and\",\n",
    "                                       \"description <> '' and\",\n",
    "                                       \"channel is not null and\",\n",
    "                                       \"channel <> '' and\",\n",
    "                                       \"channel in ('chat','facebook')\"])\n",
    "    \n",
    "    dataframe_bigquery = pandas_gbq.read_gbq(statement_bigquery_sql,project_id='findcsystem', credentials=Credentials, dialect='standard')\n",
    "\n",
    "    return dataframe_bigquery\n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for transform text to lower case\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "Output: [\"text_1\",\"text_2\"]\n",
    "\"\"\"\n",
    "def lowerCase(Corpus):\n",
    "    corpus = [i.lower().replace('\\n',' ') for i in Corpus]\n",
    "    return corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for delete punctuation form text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "################################################Output: [\"Text_1\",\"Text_2\"]\n",
    "\"\"\"\n",
    "def clearPunctuation(Corpus):\n",
    "    corpus = [i.translate(str.maketrans('', '', string.punctuation)) for i in Corpus]\n",
    "    return corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for getting language of text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "Output: [\"en\",\"ru\"]\n",
    "\"\"\"\n",
    "def getTextLanguage(Corpus):\n",
    "    txt_lang = []\n",
    "    for txt in Corpus:\n",
    "        try:\n",
    "            lang = detect(txt)\n",
    "            txt_lang.append(lang)\n",
    "        except:\n",
    "            lang = 'error'\n",
    "            txt_lang.append(lang)\n",
    "    \n",
    "    return txt_lang\n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for tokenization text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"word1 word2\",\"word3 word4\"]\n",
    "Output: [[\"word1\",\"word2\"],[\"word3\",\"word4\"]]\n",
    "\"\"\"  \n",
    "def textToTokens(Corpus):\n",
    "    corpus = [i.split() for i in Corpus]\n",
    "    return corpus \n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for clear text after garbage\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "Substr - string, regular expression\n",
    "Garbage - list of string\n",
    "[example]\n",
    "Input: Corpus = [[\"word1\",\"word2\"],[\"word3\",\"word4\"]]\n",
    "       Substr = r'word1'\n",
    "Output: [[\"word2\"],[\"word3\",\"word4\"]]\n",
    "\"\"\"  \n",
    "def clearTextAfterGarbage(Corpus,Substr):\n",
    "    clear_corpus = []\n",
    "    for text in Corpus:\n",
    "        indexes = []\n",
    "        text_len = len(text)\n",
    "        try:\n",
    "            for i in range(0,text_len):\n",
    "                res = re.search(Substr,text[i])\n",
    "                if res != None:\n",
    "                    indexes.append(i)\n",
    "                \n",
    "            #delete garbage word from text\n",
    "            for index in indexes:\n",
    "                del text[index]\n",
    "        \n",
    "            clear_corpus.append(text)\n",
    "        except:\n",
    "            #clear_corpus.append(\"error\")\n",
    "            clear_corpus.append(text) # а то слишком много ошибок\n",
    "        \n",
    "    return clear_corpus\n",
    "\n",
    "def clearTextAfterGarbageList2(Corpus,Garbage):\n",
    "    clear_corpus = Corpus\n",
    "    for Substr in Garbage:\n",
    "        clear_corpus = clearTextAfterGarbage(clear_corpus,Substr)\n",
    "    return clear_corpus    \n",
    "\n",
    "def clearTextAfterGarbageList(Corpus,Garbage):\n",
    "    clear_corpus = []\n",
    "    for text in Corpus:\n",
    "        for Substr in Garbage:\n",
    "            indexes = []\n",
    "            text_len = len(text)\n",
    "            try:\n",
    "                for i in range(0,text_len):\n",
    "                    res = re.search(Substr,text[i])\n",
    "                    if res != None:\n",
    "                        indexes.append(i)\n",
    "                \n",
    "                #delete garbage word from text\n",
    "                for index in indexes:\n",
    "                    del text[index]\n",
    "        \n",
    "                clear_corpus.append(text)\n",
    "            except:\n",
    "                #clear_corpus.append(\"error\")\n",
    "                clear_corpus.append(text) # а то слишком много ошибок\n",
    "        \n",
    "    return clear_corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for clear error after clearTextAfterGarbage(Corpus,Substr)\n",
    "[description]\n",
    "InsertDataFrame - pandas DataFrame\n",
    "[example]\n",
    "Input: InsertDataFrame = [{'description':['Text_1','error','Text_2'], field1':[1,2,3]}]}]\n",
    "Output: [{'description':['Text_1','Text_2'], field1':[1,3]}]}]\n",
    "\"\"\" \n",
    "\n",
    "def clearDescriptionError(InsertDataFrame):\n",
    "    result = pd.DataFrame()\n",
    "    result = InsertDataFrame[InsertDataFrame.description != 'error']\n",
    "    return result\n",
    "\n",
    "\"\"\"[summary]\n",
    "Build word vector by using pre-trained Word2Vec model\n",
    "[description]\n",
    "Size - lenght of vector\n",
    "Word2Vec_Model - gensim object\n",
    "\"\"\"  \n",
    "def buildWordVector(Text,Size,Word2Vec_Model):\n",
    "    vec = np.zeros(Size).reshape((1,Size))\n",
    "    count = 0.\n",
    "\n",
    "    for word in Text:\n",
    "        try:\n",
    "            vec += Word2Vec_Model[word].reshape((1,Size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def countWords(InsertDataFrame):\n",
    "    df_count = pd.DataFrame({'text':[], 'count':[]})\n",
    "\n",
    "    for row in InsertDataFrame.description:\n",
    "        for text in row:            \n",
    "            if text in df_count.text.values:\n",
    "                index = df_count[df_count.text == text].index\n",
    "                df_count.loc[index,'count'] = df_count.loc[index,'count']+1\n",
    "            else:\n",
    "                df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\n",
    "    return df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAWDATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████| 23450/23450 [00:14<00:00, 1610.04rows/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23450, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting data from dwh\n",
    "SupportRawDataframe = getDwhData(CREDENTIALS)\n",
    "SupportRawDataframe.shape\n",
    "#SupportRawDataframe.head(10)\n",
    "#SupportRawDataframe.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text to lower case\n",
    "corpus = SupportRawDataframe.description\n",
    "corpus.astype('str')\n",
    "\n",
    "corpus = clearPunctuation( lowerCase(corpus) )\n",
    "\n",
    "#getting language for text corpus\n",
    "corpus_lang = getTextLanguage(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with texts in lower case, without /n symbol and with lang for text\n",
    "SupportRawDataframe['description'] = corpus\n",
    "SupportRawDataframe['lang'] = corpus_lang\n",
    "#SupportRawDataframe.head(10)\n",
    "#SupportRawDataframe.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chat transcript visitor i want to buy with pa...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chat transcript visitor hell i had a problem ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chat transcript visitor لا استطيع الشراء ومعل...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chat transcript visitor im having trouble wit...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chat transcript visitor hi ana hello how can ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>chat transcript visitor hi i made a pruchase ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>chat transcript visitor hi how long will it t...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>chat transcript visitor i bought playerunknow...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>chat transcript visitor good day i took the w...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>chat transcript visitor hi visitor hello visi...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0       chat transcript visitor i want to buy with pa...    chat       ps   \n",
       "1       chat transcript visitor hell i had a problem ...    chat       ps   \n",
       "2       chat transcript visitor لا استطيع الشراء ومعل...    chat       ps   \n",
       "3       chat transcript visitor im having trouble wit...    chat       ps   \n",
       "4       chat transcript visitor hi ana hello how can ...    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445   chat transcript visitor hi i made a pruchase ...    chat    other   \n",
       "23446   chat transcript visitor hi how long will it t...    chat    other   \n",
       "23447   chat transcript visitor i bought playerunknow...    chat    other   \n",
       "23448   chat transcript visitor good day i took the w...    chat    other   \n",
       "23449   chat transcript visitor hi visitor hello visi...    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16176 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting only en texts\n",
    "SupportDataframe_eng = SupportRawDataframe[SupportRawDataframe.lang == 'en'][:]\n",
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text tekenization\n",
    "tokenization = textToTokens(SupportDataframe_eng.description)\n",
    "SupportDataframe_eng['description'] = tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[chat, transcript, visitor, i, want, to, buy, ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chat, transcript, visitor, hell, i, had, a, p...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[chat, transcript, visitor, لا, استطيع, الشراء...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[chat, transcript, visitor, im, having, troubl...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[chat, transcript, visitor, hi, ana, hello, ho...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>[chat, transcript, visitor, hi, i, made, a, pr...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>[chat, transcript, visitor, hi, how, long, wil...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>[chat, transcript, visitor, i, bought, playeru...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>[chat, transcript, visitor, good, day, i, took...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>[chat, transcript, visitor, hi, visitor, hello...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0      [chat, transcript, visitor, i, want, to, buy, ...    chat       ps   \n",
       "1      [chat, transcript, visitor, hell, i, had, a, p...    chat       ps   \n",
       "2      [chat, transcript, visitor, لا, استطيع, الشراء...    chat       ps   \n",
       "3      [chat, transcript, visitor, im, having, troubl...    chat       ps   \n",
       "4      [chat, transcript, visitor, hi, ana, hello, ho...    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445  [chat, transcript, visitor, hi, i, made, a, pr...    chat    other   \n",
       "23446  [chat, transcript, visitor, hi, how, long, wil...    chat    other   \n",
       "23447  [chat, transcript, visitor, i, bought, playeru...    chat    other   \n",
       "23448  [chat, transcript, visitor, good, day, i, took...    chat    other   \n",
       "23449  [chat, transcript, visitor, hi, visitor, hello...    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16176 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(SupportDataframe_eng.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text after garbage\n",
    "GarbageList = ['chat','transcript','visitor', 'hi', 'hello', 'i', 'as', 'for', 'to', 'a', 'the', 'you', 'this', 'or', 'u', 'me', 'hi', 'im', 'your', 'is', 'on', 'its', 'it', 'into']\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'chat')\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'transcript')\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'visitor')\n",
    "tests_clear = clearTextAfterGarbageList2(texts,GarbageList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[and, a, problem, us, error, code, a, screensh...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hell, a, yesterday, people, i, got, refund, i...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[لا, استطيع, الشراء, ومعلومات, الشراء, صحيحة, ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[xsolla, 4, code, a, pymaent, ana, ana, we, th...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[how, can, pay, i, credit, with, credit, canno...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>[a, 25, dollars, and, my, wallet, specified, w...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>[how, my, friend, may, with, contain, and, 31,...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>[battlegrounds, request, refund, provide, 9, s...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>[good, package, to, and, the, way, refund, so,...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>[me]</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0      [and, a, problem, us, error, code, a, screensh...    chat       ps   \n",
       "1      [hell, a, yesterday, people, i, got, refund, i...    chat       ps   \n",
       "2      [لا, استطيع, الشراء, ومعلومات, الشراء, صحيحة, ...    chat       ps   \n",
       "3      [xsolla, 4, code, a, pymaent, ana, ana, we, th...    chat       ps   \n",
       "4      [how, can, pay, i, credit, with, credit, canno...    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445  [a, 25, dollars, and, my, wallet, specified, w...    chat    other   \n",
       "23446  [how, my, friend, may, with, contain, and, 31,...    chat    other   \n",
       "23447  [battlegrounds, request, refund, provide, 9, s...    chat    other   \n",
       "23448  [good, package, to, and, the, way, refund, so,...    chat    other   \n",
       "23449                                               [me]    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16176 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupportDataframe_eng['description'] = tests_clear\n",
    "SupportDataframe_eng = clearDescriptionError(SupportDataframe_eng)\n",
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_count = pd.DataFrame({'text':[], 'count':[]})\\ndf_count0 = pd.DataFrame({'text':[]})\\n\\nfor row in SupportDataframe_eng.description:\\n    for text in row:\\n        df_count0 = df_count0.append(pd.DataFrame({'text':[text]}))               \\n        if text in df_count.text.values:\\n            index = df_count[df_count.text == text].index\\n            df_count.loc[index,'count'] = df_count.loc[index,'count']+1\\n        else:\\n            df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\\n            \\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\ndf_count2 = df_count.sort_values('count', ascending=False).iloc[:100,:]\\n#fig = plt.figure(figsize=(100,10))\\n#plt.bar(df_count2.text, df_count2['count'])\\ndf_count2.head(50)            \\n#df_count\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_count = pd.DataFrame({'text':[], 'count':[]})\n",
    "df_count0 = pd.DataFrame({'text':[]})\n",
    "\n",
    "for row in SupportDataframe_eng.description:\n",
    "    for text in row:\n",
    "        df_count0 = df_count0.append(pd.DataFrame({'text':[text]}))               \n",
    "        if text in df_count.text.values:\n",
    "            index = df_count[df_count.text == text].index\n",
    "            df_count.loc[index,'count'] = df_count.loc[index,'count']+1\n",
    "        else:\n",
    "            df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\n",
    "            \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_count2 = df_count.sort_values('count', ascending=False).iloc[:100,:]\n",
    "#fig = plt.figure(figsize=(100,10))\n",
    "#plt.bar(df_count2.text, df_count2['count'])\n",
    "df_count2.head(50)            \n",
    "#df_count'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'ps'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of unique categories\n",
    "unique_categories = np.unique(SupportDataframe_eng.category)\n",
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = SupportDataframe_eng['description']\n",
    "categories = SupportDataframe_eng['category_flag']\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(descriptions,\n",
    "                                             categories,\n",
    "                                             stratify = categories,\n",
    "                                             test_size = 0.2,\n",
    "                                             random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM TEXTS TO VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Word2Vec model for embedding words to vectors\n",
    "NDim = 100\n",
    "Imdb_w2v = Word2Vec(size = NDim,min_count = 10)\n",
    "#Imdb_w2v.build_vocab(XTrain)\n",
    "Imdb_w2v.build_vocab(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200185, 3266335)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_w2v.train(XTrain,total_examples = Imdb_w2v.corpus_count,epochs = Imdb_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding training messages to vectors for neutral classifier\n",
    "TrainVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in XTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43586432, -0.3959808 , -0.01990268, ...,  0.66250673,\n",
       "        -0.39381805,  0.31354541],\n",
       "       [-0.21275633, -0.67683196,  0.20512251, ...,  0.60520251,\n",
       "        -0.25326288,  0.28399209],\n",
       "       [-0.19479879, -0.39241365,  0.08012048, ...,  0.74108996,\n",
       "        -0.28729453,  0.22459949],\n",
       "       ...,\n",
       "       [-0.42994174, -0.54227297,  0.03541817, ...,  0.61616622,\n",
       "        -0.41158503,  0.06789512],\n",
       "       [-0.52070432, -0.62364154,  0.00704202, ...,  0.92890784,\n",
       "        -0.28629432,  0.46993134],\n",
       "       [-0.01574008, -0.40637667,  0.15611375, ...,  0.54203011,\n",
       "        -0.12883063,  0.19917874]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541733, 807410)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_w2v.train(XTest, total_examples = Imdb_w2v.corpus_count, epochs = Imdb_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in XTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14535375, -0.51181917,  0.00454482, ...,  0.65385855,\n",
       "        -0.07724295,  0.41435156],\n",
       "       [ 0.05663901, -1.20904526,  0.12860918, ...,  0.50547934,\n",
       "         0.36272812,  0.0336782 ],\n",
       "       [-0.03271364, -0.33371408,  0.14655118, ...,  0.61399629,\n",
       "        -0.21952226, -0.07903461],\n",
       "       ...,\n",
       "       [-0.20673065, -0.3120412 ,  0.2128201 , ...,  0.61218973,\n",
       "         0.07239278, -0.01282447],\n",
       "       [-0.49525105, -0.11586727, -0.08771099, ...,  0.30783819,\n",
       "        -0.03695738,  0.33467935],\n",
       "       [-0.04624643, -0.37248702,  0.00967495, ...,  0.74459834,\n",
       "        -0.29364556,  0.32198195]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSSVALIDATION AND BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextClassifier = MLPClassifier(hidden_layer_sizes = (20,10), max_iter = 1000, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88639876 0.88485317 0.87789799 0.88330757 0.88060278]\n",
      "0.8826120556414219\n"
     ]
    }
   ],
   "source": [
    "Scores = cross_val_score(TextClassifier, TrainVecs, YTrain, cv = 5)\n",
    "print(Scores)\n",
    "print(np.mean(Scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=40, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextClassifier.fit(TrainVecs,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 371  282]\n",
      " [ 116 2467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65       653\n",
      "           1       0.90      0.96      0.93      2583\n",
      "\n",
      "    accuracy                           0.88      3236\n",
      "   macro avg       0.83      0.76      0.79      3236\n",
      "weighted avg       0.87      0.88      0.87      3236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = TextClassifier.predict(TestVecs)\n",
    "print(confusion_matrix(YTest,pred))\n",
    "print(classification_report(YTest,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.33      0.45      2400\n",
      "           1       0.66      0.92      0.77      3357\n",
      "\n",
      "    accuracy                           0.67      5757\n",
      "   macro avg       0.70      0.62      0.61      5757\n",
      "weighted avg       0.70      0.67      0.64      5757\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.60      0.46       864\n",
      "           1       0.91      0.80      0.86      4594\n",
      "\n",
      "    accuracy                           0.77      5458\n",
      "   macro avg       0.64      0.70      0.66      5458\n",
      "weighted avg       0.83      0.77      0.79      5458\n",
      "\n",
      "mean roc_auc 0.6636018962525408\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, random_state=40, shuffle=False)\n",
    "MLPClassifier_sum = int(0)\n",
    "\n",
    "NDim = 100\n",
    "\n",
    "for train_index, test_index in skf.split(descriptions, categories):\n",
    "    Imdb_w2v = Word2Vec(size = NDim,min_count = 10)\n",
    "    #Imdb_w2v.build_vocab(descriptions.loc[descriptions.index.intersection(train_index)])\n",
    "    Imdb_w2v.build_vocab(descriptions)\n",
    "    Imdb_w2v.train(descriptions.loc[descriptions.index.intersection(train_index)],total_examples = Imdb_w2v.corpus_count,epochs = Imdb_w2v.epochs)\n",
    "    TrainVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in descriptions.loc[descriptions.index.intersection(train_index)]])\n",
    "    Imdb_w2v.train(descriptions.loc[descriptions.index.intersection(test_index)], total_examples = Imdb_w2v.corpus_count, epochs = Imdb_w2v.epochs)\n",
    "    TestVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in descriptions.loc[descriptions.index.intersection(test_index)]])\n",
    "    \n",
    "    TextClassifier.fit(TrainVecs,categories.loc[categories.index.intersection(train_index)])\n",
    "    MLPClassifier_sum += roc_auc_score(categories.loc[categories.index.intersection(test_index)], TextClassifier.predict(TestVecs))\n",
    "    print(classification_report(categories.loc[categories.index.intersection(test_index)],TextClassifier.predict(TestVecs)))\n",
    "MLPClassifier_total = MLPClassifier_sum / skf.get_n_splits()\n",
    "print('mean roc_auc', MLPClassifier_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зависит ли точность модели от симметричности категорий рандомной выборки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но тут рассмотрим слова в ошибочно отнесённых записях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of wrong predictions\n",
    "error_zero = list()\n",
    "error_one = list()\n",
    "for i in range(YTest.size):\n",
    "    if YTest.iloc[i] == 0:\n",
    "        if YTest.iloc[i] != pred[i]:\n",
    "            error_zero.append(YTest.index[i])\n",
    "    else:\n",
    "        if YTest.iloc[i] != pred[i]:\n",
    "            error_one.append(YTest.index[i])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error_zero = SupportDataframe_eng[SupportDataframe_eng.index.isin(error_zero)]\n",
    "df_error_one = SupportDataframe_eng[SupportDataframe_eng.index.isin(error_one)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_error_zero = countWords(df_error_zero)\n",
    "words_error_one = countWords(df_error_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cant</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sorry</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reasons</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>check</td>\n",
       "      <td>15820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>15819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>15819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visitor</td>\n",
       "      <td>15819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funds</td>\n",
       "      <td>15819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>15818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hours</td>\n",
       "      <td>15818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>15818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understanding</td>\n",
       "      <td>15817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trying</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventure</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chose</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alavliable</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>same</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clarify</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>payment</td>\n",
       "      <td>15816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method</td>\n",
       "      <td>15814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>15813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>try</td>\n",
       "      <td>15813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>15813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>or</td>\n",
       "      <td>15812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support</td>\n",
       "      <td>15812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friend</td>\n",
       "      <td>15812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worked</td>\n",
       "      <td>15810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ian</td>\n",
       "      <td>15810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>15809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>message</td>\n",
       "      <td>15809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>showed</td>\n",
       "      <td>15809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we</td>\n",
       "      <td>15806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pass</td>\n",
       "      <td>15805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our</td>\n",
       "      <td>15805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now</td>\n",
       "      <td>15805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>might</td>\n",
       "      <td>15805.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text    count\n",
       "0            how  15820.0\n",
       "0              i  15820.0\n",
       "0           cant  15820.0\n",
       "0           have  15820.0\n",
       "0           1049  15820.0\n",
       "0          sorry  15820.0\n",
       "0        reasons  15820.0\n",
       "0            for  15820.0\n",
       "0         please  15820.0\n",
       "0           will  15820.0\n",
       "0          check  15820.0\n",
       "0             it  15819.0\n",
       "0            the  15819.0\n",
       "0        visitor  15819.0\n",
       "0          funds  15819.0\n",
       "0             to  15818.0\n",
       "0          hours  15818.0\n",
       "0            you  15818.0\n",
       "0  understanding  15817.0\n",
       "0          thank  15816.0\n",
       "0         trying  15816.0\n",
       "0      adventure  15816.0\n",
       "0          chose  15816.0\n",
       "0            not  15816.0\n",
       "0     alavliable  15816.0\n",
       "0             my  15816.0\n",
       "0        country  15816.0\n",
       "0           card  15816.0\n",
       "0           from  15816.0\n",
       "0           same  15816.0\n",
       "0          could  15816.0\n",
       "0        clarify  15816.0\n",
       "0        payment  15816.0\n",
       "0         method  15814.0\n",
       "0             in  15813.0\n",
       "0            try  15813.0\n",
       "0           with  15813.0\n",
       "0             or  15812.0\n",
       "0        support  15812.0\n",
       "0         friend  15812.0\n",
       "0         worked  15810.0\n",
       "0            ian  15810.0\n",
       "0           file  15809.0\n",
       "0        message  15809.0\n",
       "0         showed  15809.0\n",
       "0             we  15806.0\n",
       "0           pass  15805.0\n",
       "0            our  15805.0\n",
       "0            now  15805.0\n",
       "0          might  15805.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_error_zero.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joel</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pay</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314980885</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>3348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>might</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>investigate</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>couple</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patience</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visitor</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yea</td>\n",
       "      <td>3347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2699</td>\n",
       "      <td>3346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td>3344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank</td>\n",
       "      <td>3344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are</td>\n",
       "      <td>3344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>then</td>\n",
       "      <td>3344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out</td>\n",
       "      <td>3343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back</td>\n",
       "      <td>3343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allow</td>\n",
       "      <td>3342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>3342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does</td>\n",
       "      <td>3341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solve</td>\n",
       "      <td>3341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opera</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>firefox</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that</td>\n",
       "      <td>3340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>3338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upload</td>\n",
       "      <td>3338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>send</td>\n",
       "      <td>3338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request</td>\n",
       "      <td>3338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is</td>\n",
       "      <td>3335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page</td>\n",
       "      <td>3335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closed</td>\n",
       "      <td>3335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>should</td>\n",
       "      <td>3334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wait</td>\n",
       "      <td>3334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>3333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>payment</td>\n",
       "      <td>3328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text   count\n",
       "0      problem  3348.0\n",
       "0         joel  3348.0\n",
       "0          how  3348.0\n",
       "0          can  3348.0\n",
       "0            i  3348.0\n",
       "0          pay  3348.0\n",
       "0    314980885  3348.0\n",
       "0          and  3348.0\n",
       "0        might  3347.0\n",
       "0           to  3347.0\n",
       "0  investigate  3347.0\n",
       "0          not  3347.0\n",
       "0            a  3347.0\n",
       "0       couple  3347.0\n",
       "0        thank  3347.0\n",
       "0          you  3347.0\n",
       "0     patience  3347.0\n",
       "0      visitor  3347.0\n",
       "0         with  3347.0\n",
       "0          see  3347.0\n",
       "0          yea  3347.0\n",
       "0           in  3346.0\n",
       "0          was  3346.0\n",
       "0         2699  3346.0\n",
       "0        could  3344.0\n",
       "0         bank  3344.0\n",
       "0          are  3344.0\n",
       "0         then  3344.0\n",
       "0          out  3343.0\n",
       "0         back  3343.0\n",
       "0        allow  3342.0\n",
       "0          the  3342.0\n",
       "0         does  3341.0\n",
       "0        solve  3341.0\n",
       "0       please  3340.0\n",
       "0        using  3340.0\n",
       "0        opera  3340.0\n",
       "0      firefox  3340.0\n",
       "0         that  3340.0\n",
       "0         file  3338.0\n",
       "0       upload  3338.0\n",
       "0         send  3338.0\n",
       "0      request  3338.0\n",
       "0           is  3335.0\n",
       "0         page  3335.0\n",
       "0       closed  3335.0\n",
       "0       should  3334.0\n",
       "0         wait  3334.0\n",
       "0        clear  3333.0\n",
       "0      payment  3328.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_error_one.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
