{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do:\n",
    "1. Текст был очищен только от одного мусорного элемента в качестве примера. Исследуйте данные через ноутбук или через веб-интерфейс BigQuery на предмет других мусорных элементов в тексте, которые не несут в себе никакого особого смысла, а только создают шум в данных. Доработайте функцию очистки тектосвых данных, чтобы в нее можно было передать список ненужного мусора и разом выполнялась очистка\n",
    "2. Проведите стратифицировнную кросс-валидацию нейросетевого классификатора https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "3. Реверс-инжениринг нейронной сети (вектор - фразы - частотный анализ встречаемых слов - удаление или добавление в модель)\n",
    "\n",
    "НЕ НАДО 3. Поэксперементируйте с гиперпараметрами нейросетевого классификатора, постарайтесь повысить качество его работы\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "4. Попробуйте использовать не Word2Vec для получения векторого представления текста, а TF-IDF преобразование http://zabaykin.ru/?p=558 http://nlpx.net/archives/57\n",
    "5. Попробуйте использовать более тонко настриваемые алгоритмы нейросетей, например из этого видео https://www.youtube.com/watch?v=cPkH1k3U1c8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import datetime as dt\n",
    "\n",
    "from langdetect import detect\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion for getting fresh data from DWH for workload model\n",
    "\"\"\"[summary]\n",
    "Funtion for getting fresh data from BigQuery for workload scoring model\n",
    "[description]\n",
    "Credentials - google service account object with credentials data for project\n",
    "[example]\n",
    "Input: Credentials = credentials_object\n",
    "Output: description\t                                        channel\t category\tcategory_flag\n",
    "        \\nChat transcript:\\nVisitor: I want to buy wit...\tchat\t ps\t        1\n",
    "        \\nChat transcript:\\nVisitor: hell i had a prob...\tchat\t ps\t        1\n",
    "        \\nChat transcript:\\nVisitor: لا استطيع الشراء ...\t chat\t  ps\t     1\n",
    "\"\"\"\n",
    "def getDwhData(Credentials):\n",
    "    statement_bigquery_sql = \" \".join([\"select description, channel, case\",\n",
    "                                       \"when manual_category in ('payment_problem','how_to_pay','howtopay','how_to_play','paystation_error','ps_problem','ps_declined') then 'ps'\",\n",
    "                                       \"else 'other'\",\n",
    "                                       \"end as category,\",\n",
    "                                       \"case\",\n",
    "                                       \"when manual_category in ('payment_problem','how_to_pay','howtopay','how_to_play','paystation_error','ps_problem','ps_declined') then 0\",\n",
    "                                       \"else 1\",\n",
    "                                       \"end as category_flag\",\n",
    "                                       \"from `xsolla_summer_school.customer_support`\",\n",
    "                                       \"where manual_category is not null and\",\n",
    "                                       \"manual_category <> '' and\",\n",
    "                                       \"description is not null and\",\n",
    "                                       \"description <> '' and\",\n",
    "                                       \"channel is not null and\",\n",
    "                                       \"channel <> '' and\",\n",
    "                                       \"channel in ('chat','facebook')\"])\n",
    "    \n",
    "    dataframe_bigquery = pandas_gbq.read_gbq(statement_bigquery_sql,project_id='findcsystem', credentials=Credentials, dialect='standard')\n",
    "\n",
    "    return dataframe_bigquery\n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for transform text to lower case\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "Output: [\"text_1\",\"text_2\"]\n",
    "\"\"\"\n",
    "def lowerCase(Corpus):\n",
    "    corpus = [i.lower().replace('\\n',' ') for i in Corpus]\n",
    "    return corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for delete punctuation form text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "################################################Output: [\"Text_1\",\"Text_2\"]\n",
    "\"\"\"\n",
    "def clearPunctuation(Corpus):\n",
    "    corpus = [i.translate(str.maketrans('', '', string.punctuation)) for i in Corpus]\n",
    "    return corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for getting language of text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"Text_1\",\"Text_2\"]\n",
    "Output: [\"en\",\"ru\"]\n",
    "\"\"\"\n",
    "def getTextLanguage(Corpus):\n",
    "    txt_lang = []\n",
    "    for txt in Corpus:\n",
    "        try:\n",
    "            lang = detect(txt)\n",
    "            txt_lang.append(lang)\n",
    "        except:\n",
    "            lang = 'error'\n",
    "            txt_lang.append(lang)\n",
    "    \n",
    "    return txt_lang\n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for tokenization text\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "[example]\n",
    "Input: Corpus = [\"word1 word2\",\"word3 word4\"]\n",
    "Output: [[\"word1\",\"word2\"],[\"word3\",\"word4\"]]\n",
    "\"\"\"  \n",
    "def textToTokens(Corpus):\n",
    "    corpus = [i.split() for i in Corpus]\n",
    "    return corpus \n",
    "\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for clear text after garbage\n",
    "[description]\n",
    "Corpus - list or array object, with text data\n",
    "Substr - string, regular expression\n",
    "Garbage - list of string\n",
    "[example]\n",
    "Input: Corpus = [[\"word1\",\"word2\"],[\"word3\",\"word4\"]]\n",
    "       Substr = r'word1'\n",
    "Output: [[\"word2\"],[\"word3\",\"word4\"]]\n",
    "\"\"\"  \n",
    "def clearTextAfterGarbage(Corpus,Substr):\n",
    "    clear_corpus = []\n",
    "    for text in Corpus:\n",
    "        indexes = []\n",
    "        text_len = len(text)\n",
    "        try:\n",
    "            for i in range(0,text_len):\n",
    "                res = re.search(Substr,text[i])\n",
    "                if res != None:\n",
    "                    indexes.append(i)\n",
    "                \n",
    "            #delete garbage word from text\n",
    "            for index in indexes:\n",
    "                del text[index]\n",
    "        \n",
    "            clear_corpus.append(text)\n",
    "        except:\n",
    "            #clear_corpus.append(\"error\")\n",
    "            clear_corpus.append(text) # а то слишком много ошибок\n",
    "        \n",
    "    return clear_corpus\n",
    "\n",
    "def clearTextAfterGarbageList2(Corpus,Garbage):\n",
    "    clear_corpus = Corpus\n",
    "    for Substr in Garbage:\n",
    "        clear_corpus = clearTextAfterGarbage(clear_corpus,Substr)\n",
    "    return clear_corpus    \n",
    "\n",
    "def clearTextAfterGarbageList(Corpus,Garbage):\n",
    "    clear_corpus = []\n",
    "    for text in Corpus:\n",
    "        for Substr in Garbage:\n",
    "            indexes = []\n",
    "            text_len = len(text)\n",
    "            try:\n",
    "                for i in range(0,text_len):\n",
    "                    res = re.search(Substr,text[i])\n",
    "                    if res != None:\n",
    "                        indexes.append(i)\n",
    "                \n",
    "                #delete garbage word from text\n",
    "                for index in indexes:\n",
    "                    del text[index]\n",
    "        \n",
    "                clear_corpus.append(text)\n",
    "            except:\n",
    "                #clear_corpus.append(\"error\")\n",
    "                clear_corpus.append(text) # а то слишком много ошибок\n",
    "        \n",
    "    return clear_corpus\n",
    "\n",
    "\"\"\"[summary]\n",
    "Function for clear error after clearTextAfterGarbage(Corpus,Substr)\n",
    "[description]\n",
    "InsertDataFrame - pandas DataFrame\n",
    "[example]\n",
    "Input: InsertDataFrame = [{'description':['Text_1','error','Text_2'], field1':[1,2,3]}]}]\n",
    "Output: [{'description':['Text_1','Text_2'], field1':[1,3]}]}]\n",
    "\"\"\" \n",
    "\n",
    "def clearDescriptionError(InsertDataFrame):\n",
    "    result = pd.DataFrame()\n",
    "    result = InsertDataFrame[InsertDataFrame.description != 'error']\n",
    "    return result\n",
    "\n",
    "\"\"\"[summary]\n",
    "Build word vector by using pre-trained Word2Vec model\n",
    "[description]\n",
    "Size - lenght of vector\n",
    "Word2Vec_Model - gensim object\n",
    "\"\"\"  \n",
    "def buildWordVector(Text,Size,Word2Vec_Model):\n",
    "    vec = np.zeros(Size).reshape((1,Size))\n",
    "    count = 0.\n",
    "\n",
    "    for word in Text:\n",
    "        try:\n",
    "            vec += Word2Vec_Model[word].reshape((1,Size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def countWords(InsertDataFrame):\n",
    "    df_count = pd.DataFrame({'text':[], 'count':[]})\n",
    "\n",
    "    for row in InsertDataFrame.description:\n",
    "        for text in row:            \n",
    "            if text in df_count.text.values:\n",
    "                index = df_count[df_count.text == text].index\n",
    "                df_count.loc[index,'count'] = df_count.loc[index,'count']+1\n",
    "            else:\n",
    "                df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\n",
    "    return df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAWDATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████| 23450/23450 [00:51<00:00, 454.53rows/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23450, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting data from dwh\n",
    "SupportRawDataframe = getDwhData(CREDENTIALS)\n",
    "SupportRawDataframe.shape\n",
    "#SupportRawDataframe.head(10)\n",
    "#SupportRawDataframe.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text to lower case\n",
    "corpus = SupportRawDataframe.description\n",
    "corpus.astype('str')\n",
    "\n",
    "corpus = clearPunctuation( lowerCase(corpus) )\n",
    "\n",
    "#getting language for text corpus\n",
    "corpus_lang = getTextLanguage(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe with texts in lower case, without /n symbol and with lang for text\n",
    "SupportRawDataframe['description'] = corpus\n",
    "SupportRawDataframe['lang'] = corpus_lang\n",
    "#SupportRawDataframe.head(10)\n",
    "#SupportRawDataframe.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chat transcript visitor i want to buy with pa...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chat transcript visitor hell i had a problem ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chat transcript visitor لا استطيع الشراء ومعل...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chat transcript visitor im having trouble wit...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chat transcript visitor hi ana hello how can ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>chat transcript visitor hi i made a pruchase ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>chat transcript visitor hi how long will it t...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>chat transcript visitor i bought playerunknow...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>chat transcript visitor good day i took the w...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>chat transcript visitor hi visitor hello visi...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16141 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0       chat transcript visitor i want to buy with pa...    chat       ps   \n",
       "1       chat transcript visitor hell i had a problem ...    chat       ps   \n",
       "2       chat transcript visitor لا استطيع الشراء ومعل...    chat       ps   \n",
       "3       chat transcript visitor im having trouble wit...    chat       ps   \n",
       "4       chat transcript visitor hi ana hello how can ...    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445   chat transcript visitor hi i made a pruchase ...    chat    other   \n",
       "23446   chat transcript visitor hi how long will it t...    chat    other   \n",
       "23447   chat transcript visitor i bought playerunknow...    chat    other   \n",
       "23448   chat transcript visitor good day i took the w...    chat    other   \n",
       "23449   chat transcript visitor hi visitor hello visi...    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16141 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting only en texts\n",
    "SupportDataframe_eng = SupportRawDataframe[SupportRawDataframe.lang == 'en'][:]\n",
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text tekenization\n",
    "tokenization = textToTokens(SupportDataframe_eng.description)\n",
    "SupportDataframe_eng['description'] = tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[chat, transcript, visitor, i, want, to, buy, ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chat, transcript, visitor, hell, i, had, a, p...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[chat, transcript, visitor, لا, استطيع, الشراء...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[chat, transcript, visitor, im, having, troubl...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[chat, transcript, visitor, hi, ana, hello, ho...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>[chat, transcript, visitor, hi, i, made, a, pr...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>[chat, transcript, visitor, hi, how, long, wil...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>[chat, transcript, visitor, i, bought, playeru...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>[chat, transcript, visitor, good, day, i, took...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>[chat, transcript, visitor, hi, visitor, hello...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16141 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0      [chat, transcript, visitor, i, want, to, buy, ...    chat       ps   \n",
       "1      [chat, transcript, visitor, hell, i, had, a, p...    chat       ps   \n",
       "2      [chat, transcript, visitor, لا, استطيع, الشراء...    chat       ps   \n",
       "3      [chat, transcript, visitor, im, having, troubl...    chat       ps   \n",
       "4      [chat, transcript, visitor, hi, ana, hello, ho...    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445  [chat, transcript, visitor, hi, i, made, a, pr...    chat    other   \n",
       "23446  [chat, transcript, visitor, hi, how, long, wil...    chat    other   \n",
       "23447  [chat, transcript, visitor, i, bought, playeru...    chat    other   \n",
       "23448  [chat, transcript, visitor, good, day, i, took...    chat    other   \n",
       "23449  [chat, transcript, visitor, hi, visitor, hello...    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16141 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(SupportDataframe_eng.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text after garbage\n",
    "GarbageList = ['chat','transcript','visitor', 'hi', 'hello', 'i', 'as', 'for', 'to', 'a', 'the', 'you', 'this', 'or', 'u', 'me', 'hi', 'im', 'your', 'is', 'on', 'its', 'it', 'into']\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'chat')\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'transcript')\n",
    "#tests_clear = clearTextAfterGarbage(texts,r'visitor')\n",
    "tests_clear = clearTextAfterGarbageList2(texts,GarbageList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>category_flag</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[a, code, a, screenshot, error, an, as, few, t...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hell, yesterday, got, i, but, a, 4, gifted, a...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[لا, استطيع, الشراء, ومعلومات, الشراء, صحيحة, ...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, code, a, ana, we, a, placed, on, 1, twice,...</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[how, pay, card, credit]</td>\n",
       "      <td>chat</td>\n",
       "      <td>ps</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>[25, dollars, my, specified, by, been, i, sent...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23446</th>\n",
       "      <td>[how, my, friend, contain, with, details, will...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23447</th>\n",
       "      <td>[refund, 25, received, all, details, alexandra...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23448</th>\n",
       "      <td>[good, and, way, can, two, resolve, transactio...</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23449</th>\n",
       "      <td>[]</td>\n",
       "      <td>chat</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16141 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description channel category  \\\n",
       "0      [a, code, a, screenshot, error, an, as, few, t...    chat       ps   \n",
       "1      [hell, yesterday, got, i, but, a, 4, gifted, a...    chat       ps   \n",
       "2      [لا, استطيع, الشراء, ومعلومات, الشراء, صحيحة, ...    chat       ps   \n",
       "3      [4, code, a, ana, we, a, placed, on, 1, twice,...    chat       ps   \n",
       "4                               [how, pay, card, credit]    chat       ps   \n",
       "...                                                  ...     ...      ...   \n",
       "23445  [25, dollars, my, specified, by, been, i, sent...    chat    other   \n",
       "23446  [how, my, friend, contain, with, details, will...    chat    other   \n",
       "23447  [refund, 25, received, all, details, alexandra...    chat    other   \n",
       "23448  [good, and, way, can, two, resolve, transactio...    chat    other   \n",
       "23449                                                 []    chat    other   \n",
       "\n",
       "       category_flag lang  \n",
       "0                  0   en  \n",
       "1                  0   en  \n",
       "2                  0   en  \n",
       "3                  0   en  \n",
       "4                  0   en  \n",
       "...              ...  ...  \n",
       "23445              1   en  \n",
       "23446              1   en  \n",
       "23447              1   en  \n",
       "23448              1   en  \n",
       "23449              1   en  \n",
       "\n",
       "[16141 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupportDataframe_eng['description'] = tests_clear\n",
    "SupportDataframe_eng = clearDescriptionError(SupportDataframe_eng)\n",
    "SupportDataframe_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_count = pd.DataFrame({'text':[], 'count':[]})\\ndf_count0 = pd.DataFrame({'text':[]})\\n\\nfor row in SupportDataframe_eng.description:\\n    for text in row:\\n        df_count0 = df_count0.append(pd.DataFrame({'text':[text]}))               \\n        if text in df_count.text.values:\\n            index = df_count[df_count.text == text].index\\n            df_count.loc[index,'count'] = df_count.loc[index,'count']+1\\n        else:\\n            df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\\n            \\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\ndf_count2 = df_count.sort_values('count', ascending=False).iloc[:100,:]\\n#fig = plt.figure(figsize=(100,10))\\n#plt.bar(df_count2.text, df_count2['count'])\\ndf_count2.head(50)            \\n#df_count\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_count = pd.DataFrame({'text':[], 'count':[]})\n",
    "df_count0 = pd.DataFrame({'text':[]})\n",
    "\n",
    "for row in SupportDataframe_eng.description:\n",
    "    for text in row:\n",
    "        df_count0 = df_count0.append(pd.DataFrame({'text':[text]}))               \n",
    "        if text in df_count.text.values:\n",
    "            index = df_count[df_count.text == text].index\n",
    "            df_count.loc[index,'count'] = df_count.loc[index,'count']+1\n",
    "        else:\n",
    "            df_count = df_count.append(pd.DataFrame({'text':text, 'count':[int(1)]}))\n",
    "            \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_count2 = df_count.sort_values('count', ascending=False).iloc[:100,:]\n",
    "#fig = plt.figure(figsize=(100,10))\n",
    "#plt.bar(df_count2.text, df_count2['count'])\n",
    "df_count2.head(50)            \n",
    "#df_count'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'ps'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of unique categories\n",
    "unique_categories = np.unique(SupportDataframe_eng.category)\n",
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = SupportDataframe_eng['description']\n",
    "categories = SupportDataframe_eng['category_flag']\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(descriptions,\n",
    "                                             categories,\n",
    "                                             stratify = categories,\n",
    "                                             test_size = 0.2,\n",
    "                                             random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM TEXTS TO VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Word2Vec model for embedding words to vectors\n",
    "NDim = 100\n",
    "Imdb_w2v = Word2Vec(size = NDim,min_count = 10)\n",
    "Imdb_w2v.build_vocab(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878657, 1304860)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_w2v.train(XTrain,total_examples = Imdb_w2v.corpus_count,epochs = Imdb_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding training messages to vectors for neutral classifier\n",
    "TrainVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in XTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41770694, -0.13749716, -0.04865682, ...,  0.05241149,\n",
       "        -0.03612048,  0.10137637],\n",
       "       [ 0.49398091, -0.00422621,  0.08119957, ...,  0.12447836,\n",
       "         0.0861813 ,  0.25740374],\n",
       "       [ 0.38184024, -0.07130834,  0.10378505, ...,  0.2060302 ,\n",
       "         0.08443201,  0.26127128],\n",
       "       ...,\n",
       "       [ 0.47963359,  0.04692873,  0.11349692, ...,  0.21846799,\n",
       "         0.06216082,  0.14397052],\n",
       "       [ 0.43374576, -0.06246465,  0.2496388 , ...,  0.15147051,\n",
       "        -0.10502954,  0.34311489],\n",
       "       [ 0.47096798,  0.01148131,  0.13035181, ...,  0.16968209,\n",
       "         0.04469057,  0.14918907]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220782, 328805)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_w2v.train(XTest, total_examples = Imdb_w2v.corpus_count, epochs = Imdb_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in XTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21701333, -0.07734585, -0.01326046, ..., -0.01822665,\n",
       "        -0.10563625,  0.15623976],\n",
       "       [ 0.40639109,  0.09373962,  0.15100237, ...,  0.12765931,\n",
       "         0.04488374,  0.11340171],\n",
       "       [ 0.60968511,  0.3570559 ,  0.42759349, ...,  0.38786559,\n",
       "        -0.13404563,  0.04923485],\n",
       "       ...,\n",
       "       [ 0.44847175,  0.07205314, -0.44483176, ...,  0.37589905,\n",
       "         0.47444311, -0.08229289],\n",
       "       [ 0.30208631, -0.06710074, -0.06477036, ...,  0.11963807,\n",
       "         0.15459059,  0.06940154],\n",
       "       [ 0.29998545, -0.14695022, -0.33885496, ..., -0.27240485,\n",
       "         0.02898898,  0.13579771]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSSVALIDATION AND BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextClassifier = MLPClassifier(hidden_layer_sizes = (20,10), max_iter = 1000, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82423539 0.83894696 0.85127808 0.84314485 0.82920217]\n",
      "0.8373614885866685\n"
     ]
    }
   ],
   "source": [
    "Scores = cross_val_score(TextClassifier, TrainVecs, YTrain, cv = 5)\n",
    "print(Scores)\n",
    "print(np.mean(Scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=40, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextClassifier.fit(TrainVecs,YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 283  367]\n",
      " [ 184 2395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.44      0.51       650\n",
      "           1       0.87      0.93      0.90      2579\n",
      "\n",
      "    accuracy                           0.83      3229\n",
      "   macro avg       0.74      0.68      0.70      3229\n",
      "weighted avg       0.81      0.83      0.82      3229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = TextClassifier.predict(TestVecs)\n",
    "print(confusion_matrix(YTest,pred))\n",
    "print(classification_report(YTest,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.11      0.20      2389\n",
      "           1       0.61      0.98      0.75      3341\n",
      "\n",
      "    accuracy                           0.62      5730\n",
      "   macro avg       0.69      0.55      0.47      5730\n",
      "weighted avg       0.68      0.62      0.52      5730\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.89      0.40       861\n",
      "           1       0.96      0.52      0.68      4563\n",
      "\n",
      "    accuracy                           0.58      5424\n",
      "   macro avg       0.61      0.71      0.54      5424\n",
      "weighted avg       0.85      0.58      0.63      5424\n",
      "\n",
      "mean roc_auc 0.6252041094208673\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=2, random_state=40, shuffle=False)\n",
    "MLPClassifier_sum = int(0)\n",
    "\n",
    "NDim = 100\n",
    "\n",
    "for train_index, test_index in skf.split(descriptions, categories):\n",
    "    Imdb_w2v = Word2Vec(size = NDim,min_count = 10)\n",
    "    Imdb_w2v.build_vocab(descriptions.loc[descriptions.index.intersection(train_index)])\n",
    "    Imdb_w2v.train(descriptions.loc[descriptions.index.intersection(train_index)],total_examples = Imdb_w2v.corpus_count,epochs = Imdb_w2v.epochs)\n",
    "    TrainVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in descriptions.loc[descriptions.index.intersection(train_index)]])\n",
    "    Imdb_w2v.train(descriptions.loc[descriptions.index.intersection(test_index)], total_examples = Imdb_w2v.corpus_count, epochs = Imdb_w2v.epochs)\n",
    "    TestVecs = np.concatenate([buildWordVector(i,NDim,Imdb_w2v) for i in descriptions.loc[descriptions.index.intersection(test_index)]])\n",
    "    \n",
    "    TextClassifier.fit(TrainVecs,categories.loc[categories.index.intersection(train_index)])\n",
    "    MLPClassifier_sum += roc_auc_score(categories.loc[categories.index.intersection(test_index)], TextClassifier.predict(TestVecs))\n",
    "    print(classification_report(categories.loc[categories.index.intersection(test_index)],TextClassifier.predict(TestVecs)))\n",
    "MLPClassifier_total = MLPClassifier_sum / skf.get_n_splits()\n",
    "print('mean roc_auc', MLPClassifier_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зависит ли точность модели от симметричности категорий рандомной выборки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но тут рассмотрим слова в ошибочно отнесённых записях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of wrong predictions\n",
    "error_zero = list()\n",
    "error_one = list()\n",
    "for i in range(YTest.size):\n",
    "    if YTest.iloc[i] == 0:\n",
    "        if YTest.iloc[i] != pred[i]:\n",
    "            error_zero.append(YTest.index[i])\n",
    "    else:\n",
    "        if YTest.iloc[i] != pred[i]:\n",
    "            error_one.append(YTest.index[i])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error_zero = SupportDataframe_eng[SupportDataframe_eng.index.isin(error_zero)]\n",
    "df_error_one = SupportDataframe_eng[SupportDataframe_eng.index.isin(error_one)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_error_zero = countWords(df_error_zero)\n",
    "words_error_one = countWords(df_error_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msg</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>browser</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allow</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ian</td>\n",
       "      <td>5437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>5435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>5435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>5434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occur</td>\n",
       "      <td>5433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how</td>\n",
       "      <td>5433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>5433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>5432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credited</td>\n",
       "      <td>5432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trying</td>\n",
       "      <td>5432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when</td>\n",
       "      <td>5432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sends</td>\n",
       "      <td>5432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fails</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>send</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confirm</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>5431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retry</td>\n",
       "      <td>5430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact</td>\n",
       "      <td>5430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue</td>\n",
       "      <td>5430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>5429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>give</td>\n",
       "      <td>5429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now</td>\n",
       "      <td>5429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>5429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resolve</td>\n",
       "      <td>5428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>5428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receive</td>\n",
       "      <td>5427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>free</td>\n",
       "      <td>5427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case</td>\n",
       "      <td>5427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>5427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>help</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>am</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patience</td>\n",
       "      <td>5426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>been</td>\n",
       "      <td>5425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>url</td>\n",
       "      <td>5424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new</td>\n",
       "      <td>5424.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text   count\n",
       "0       msg  5437.0\n",
       "0   browser  5437.0\n",
       "0       out  5437.0\n",
       "0     allow  5437.0\n",
       "0      that  5437.0\n",
       "0      does  5437.0\n",
       "0       the  5437.0\n",
       "0        as  5437.0\n",
       "0       why  5437.0\n",
       "0        we  5437.0\n",
       "0       ian  5437.0\n",
       "0     right  5435.0\n",
       "0         i  5435.0\n",
       "0        to  5434.0\n",
       "0     occur  5433.0\n",
       "0       how  5433.0\n",
       "0      have  5433.0\n",
       "0    please  5432.0\n",
       "0  credited  5432.0\n",
       "0    trying  5432.0\n",
       "0      when  5432.0\n",
       "0     sends  5432.0\n",
       "0        do  5431.0\n",
       "0       and  5431.0\n",
       "0     fails  5431.0\n",
       "0      send  5431.0\n",
       "0   confirm  5431.0\n",
       "0      mean  5431.0\n",
       "0     retry  5430.0\n",
       "0   contact  5430.0\n",
       "0     issue  5430.0\n",
       "0         a  5429.0\n",
       "0      give  5429.0\n",
       "0       now  5429.0\n",
       "0      file  5429.0\n",
       "0   resolve  5428.0\n",
       "0       you  5428.0\n",
       "0   receive  5427.0\n",
       "0      free  5427.0\n",
       "0      case  5427.0\n",
       "0     thank  5427.0\n",
       "0       day  5426.0\n",
       "0      help  5426.0\n",
       "0        am  5426.0\n",
       "0      page  5426.0\n",
       "0       our  5426.0\n",
       "0  patience  5426.0\n",
       "0      been  5425.0\n",
       "0       url  5424.0\n",
       "0       new  5424.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_error_zero.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100</td>\n",
       "      <td>2220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky</td>\n",
       "      <td>2220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>2220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ian</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>possibly</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>may</td>\n",
       "      <td>2218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>could</td>\n",
       "      <td>2218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>future</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pass</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>refund</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contact</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patience</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>£716</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occurred</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recipes</td>\n",
       "      <td>2217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going</td>\n",
       "      <td>2216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what</td>\n",
       "      <td>2215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>question</td>\n",
       "      <td>2215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using</td>\n",
       "      <td>2215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and</td>\n",
       "      <td>2215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tarkov</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paypal</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page</td>\n",
       "      <td>2212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>are</td>\n",
       "      <td>2212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>processing</td>\n",
       "      <td>2212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seems</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confirm</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>2210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>2209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esea</td>\n",
       "      <td>2208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive</td>\n",
       "      <td>2205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see</td>\n",
       "      <td>2205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they</td>\n",
       "      <td>2205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>address</td>\n",
       "      <td>2205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account</td>\n",
       "      <td>2201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text   count\n",
       "0        2100  2220.0\n",
       "0         sky  2220.0\n",
       "0          no  2220.0\n",
       "0          be  2219.0\n",
       "0         ian  2219.0\n",
       "0          my  2219.0\n",
       "0    possibly  2219.0\n",
       "0         did  2219.0\n",
       "0         may  2218.0\n",
       "0       could  2218.0\n",
       "0      future  2217.0\n",
       "0          as  2217.0\n",
       "0         any  2217.0\n",
       "0      please  2217.0\n",
       "0         you  2217.0\n",
       "0        pass  2217.0\n",
       "0      refund  2217.0\n",
       "0          me  2217.0\n",
       "0        like  2217.0\n",
       "0     contact  2217.0\n",
       "0    patience  2217.0\n",
       "0        £716  2217.0\n",
       "0         got  2217.0\n",
       "0    occurred  2217.0\n",
       "0         now  2217.0\n",
       "0     recipes  2217.0\n",
       "0       going  2216.0\n",
       "0        what  2215.0\n",
       "0    question  2215.0\n",
       "0       using  2215.0\n",
       "0         and  2215.0\n",
       "0      tarkov  2213.0\n",
       "0      paypal  2213.0\n",
       "0        page  2212.0\n",
       "0         are  2212.0\n",
       "0  processing  2212.0\n",
       "0       seems  2210.0\n",
       "0     confirm  2210.0\n",
       "0   according  2210.0\n",
       "0          on  2210.0\n",
       "0         not  2210.0\n",
       "0         out  2210.0\n",
       "0          it  2210.0\n",
       "0          ok  2209.0\n",
       "0        esea  2208.0\n",
       "0         ive  2205.0\n",
       "0         see  2205.0\n",
       "0        they  2205.0\n",
       "0     address  2205.0\n",
       "0     account  2201.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_error_one.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
